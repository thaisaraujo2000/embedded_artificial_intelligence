### Portuguese version
#### Resumo do artigo "TinyMLOps: Operational Challenges for Widespread Edge AI Adoption"

O crescimento da utilização de Inteligência Artificial em dispositivos de baixo poder de processamento, campo conhecido como TinyML, nos últimos anos, tem proporcionado o surgimento de alguns desafios. Nesse sentido, o artigo “TinyMLOps: Operational Challenges for Widespread Edge AI Adoption” traz à tona a aplicação de algumas técnicas para que se possa lidar com problemáticas geradas por essa nova área, de forma a dar suporte a soluções descentralizadas, cujo recurso computacional pode variar de acordo com o dispositivo utilizado, diferentemente do que é empregado em aplicações em nuvem. Para isso, os autores discutem alguns pontos, como aspectos computacionais, o gerenciamento de versões de modelo, seu monitoramento e sua personalização, além de questões de segurança e modelo de negócios.

Atualmente, novos desafios operacionais acabam tendo que ser considerados por profissionais que trabalham com dispositivos limitados. Assim, inicialmente, o artigo apresenta uma visão geral a respeito da aplicação de modelos de machine learning em dispositivos de borda, de forma que se possa reduzir o custo operacional para colocar os modelos em produção diante da complexidade dos que já foram implementados. Em seguida, os autores mencionam o gerenciamento de versões de modelos, além da necessidade de manter uma manutenção contínua, tal como algumas “dívidas técnicas” decorrentes da ausência, por exemplo, de uma documentação, o que acaba dificultando as análises de desempenho e a detecção de erros. A partir dessas preocupações, surgiu a área de MLOps, como a presença de boas práticas em aplicações de machine learning. Dessa forma, à medida que as empresas vão crescendo, MLOps são mais difundidos, e é destacada a importância de estender esse conjunto de práticas para TinyML, surgindo o campo de TinyMLOps.

Assim, uma técnica mostrada trata-se de desenvolver versões diferentes de um modelo. Entretanto, já que há uma descentralização em TinyML, existe uma grande quantidade de modelos para serem gerenciados por um sistema TinyMLOps. Com isso, a normalização a partir do pré-processamento e do pós-processamento de dados é algo essencial. Ademais, a observabilidade e o monitoramento de modelos são fundamentais para que se possa garantir um bom funcionamento deles, uma vez que se faz necessário detectar anomalias e a degradação do desempenho. Outra forma de lidar com essa descentralização descrita no artigo é o registro do tempo real de execução, da memória e do consumo de energia de diferentes dispositivos, o que pode colaborar na criação de melhores soluções. 

Ainda, uma prática citada aplicável de maneira offline em soluções TinyMLOps seria um modelo de negócios, em que os usuários pagam por determinado tipo de consulta, por exemplo, mas é algo bastante complexo e desafiador. Além disso, a personalização de um modelo também é algo mencionado. Ela pode ser criada tendo como base o usuário que está utilizando o dispositivo de borda e, com isso, pode ter a capacidade de aprender sobre seu comportamento no decorrer do tempo. No que diz respeito à fragmentação de plataformas TinyMLOps, em decorrência da falta de padronização, tem-se containers, os quais podem ser implementados em vários dispositivos diferentes por meio da virtualização. 

Nesse sentido, com a enorme variedade de modelos, surge a necessidade de protegê-los, em vista do grande tempo que é demandado para criá-los, além de todo investimento que é aplicado para construí-los. Assim, técnicas de criptografia são essenciais para evitar plágio e proteger a propriedade intelectual. Por fim, um ponto destacado no artigo é a vantagem da implementação em borda em relação a solução em nuvem sobre a garantia de privacidade, já que os dados permanecerão nos dispositivos de forma local, caso não haja nenhum compartilhamento. Em vista disso, é possível notar que, apesar da grande quantidade de desafios existentes no contexto de TinyMLOps, já existem muitas técnicas que podem ser exploradas e aperfeiçoadas. 


#### Referência
Leroux, S.; Simoens, P.; Lootus, M.; Thakore, K.; Sharma, A.
**TinyMLOps: Operational Challenges for Widespread Edge AI Adoption.** arXiv 2022, arXiv:2203.10923v2. Disponível em: https://arxiv.org/pdf/2203.10923.pdf. Acesso em: 19 de setembro de 2022.

---

### English version
#### Summary of the paper "TinyMLOps: Operational Challenges for Widespread Edge AI Adoption"

The growth of the use of artificial intelligence on low processing devices, a field known as Tinyml, in recent years, has provided the emergence of some challenges. In this sense, the article “Tinymlops: Operational Challenges for Widespread Edge Ai Adoption” brings to the application of some techniques so that you can deal with problems generated by this new area, in order to support decentralized solutions, whose computational resource may be supported Vary according to the device used, unlike what is used in cloud applications. To this end, the authors discuss some points, such as computational aspects, model versions management, monitoring and customization, as well as safety issues and business model.

Currently, new operational challenges have to be considered by professionals working with limited devices. Thus, initially, the article presents an overview of the application of machine learning models on edge devices, so that the operating cost can be reduced to place the models in production in the face of the complexity of those that have already been implemented. Then, the authors mention the management of models versions, as well as the need to maintain continuous maintenance, such as some “technical debts” arising from the absence, for example, of a documentation, which ends up making performance analysis difficult and the Error detection. From these concerns, the MLOPS area emerged, such as the presence of good practices in Machine Learning applications. Thus, as companies grow, mlops are more widespread, and the importance of extending this set of practices for Tinyml is highlighted, the Tinymlops field appearing.

Thus, a technique shown is about developing different versions of a model. However, since there is a decentralization in Tinyml, there are a large amount of models to be managed by a Tinymlops system. As a result, standardization from pre-processing and post-processing data is essential. In addition, observability and models monitoring are fundamental to ensure a proper functioning of them as it is necessary to detect anomalies and the degradation of performance. Another way to deal with this decentralization described in the article is the registration of the real time of execution, memory and energy consumption of different devices, which can contribute to the creation of better solutions.

Still, a cited practice applicable offline in Tinymlops solutions would be a business model, where users pay for a certain type of consultation, for example, but is quite complex and challenging. In addition, the customization of a model is also mentioned. It can be created based on the user using the edge device and can have the ability to learn about their behavior over time. Regarding the fragmentation of Tinymlops platforms, due to the lack of standardization, there are containers, which can be implemented on several different devices through virtualization. In this sense, with the enormous variety of models, the need to protect them, in view of the great time that is demanded to create them, as well as every investment that is applied to build them. Thus, encryption techniques are essential to prevent plagiarism and protect intellectual property. Finally, one point highlighted in the article is the advantage of implementing in border in relation to the cloud solution about the privacy guarantee, as the data will remain on the devices locally if there is no sharing. In view of this, it is possible to note that, despite the large amount of challenges in the context of Tinymlops, there are already many techniques that can be explored and perfected.

#### Reference
Leroux, S.; Simoens, P.; Lootus, M.; Thakore, K.; Sharma, A.
TinyMLOps: Operational Challenges for Widespread Edge AI Adoption. arXiv 2022, arXiv:2203.10923v2. Available at https://arxiv.org/pdf/2203.10923.pdf (Accessed: 19 September 2022)